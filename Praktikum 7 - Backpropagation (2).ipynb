{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvonXDMsQP1k"
      },
      "source": [
        "# Bab 8 Backpropagation (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHySaU_QQPg1"
      },
      "source": [
        "## Praktikum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Fungsi *Sigmoid*, *One-Hot Encoding* dan *Decoding*"
      ],
      "metadata": {
        "id": "QunWEuwX5SLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fungsi sigmoid dan turunannya\n",
        "def sig(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigd(x):\n",
        "    return sig(x) * (1 - sig(x))\n",
        "\n",
        "# Fungsi one-hot encoding dan decoding\n",
        "def onehot_enc(target):\n",
        "    return np.eye(len(np.unique(target)))[target]\n",
        "\n",
        "def onehot_dec(encoded):\n",
        "    return np.argmax(encoded, axis=1)"
      ],
      "metadata": {
        "id": "xDXEq-1sGYHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hihqFCY_ctZ3"
      },
      "source": [
        "### b) Fungsi *Training* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTlk5igwcvc5"
      },
      "source": [
        "def bp_fit(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, print_per_epoch=100):\n",
        "    np.random.seed(1)\n",
        "    nin = [np.empty(i) for i in layer_conf]\n",
        "    n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j) for i, j in enumerate(layer_conf)]\n",
        "    w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1]) for i in range(len(layer_conf) - 1)]\n",
        "    dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1])) for i in range(len(layer_conf) - 1)]\n",
        "    d = [np.empty(s) for s in layer_conf[1:]]\n",
        "    din = [np.empty(s) for s in layer_conf[1:-1]]\n",
        "    epoch = 0\n",
        "    mse = 1\n",
        "\n",
        "    for i in range(0, len(n)-1):\n",
        "        n[i][-1] = 1\n",
        "\n",
        "    while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
        "        epoch += 1\n",
        "        mse = 0\n",
        "\n",
        "        for r in range(len(X)):\n",
        "            n[0][:-1] = X[r]\n",
        "\n",
        "            for L in range(1, len(layer_conf)):\n",
        "                nin[L] = np.dot(n[L-1], w[L-1])\n",
        "                n[L][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "            e = target[r] - n[-1]\n",
        "            mse += sum(e ** 2)\n",
        "            d[-1] = e * sigd(nin[-1])\n",
        "            dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
        "\n",
        "            for L in range(len(layer_conf) - 1, 1, -1):\n",
        "                din[L-2] = np.dot(d[L-1], np.transpose(w[L-1][:-1]))\n",
        "                d[L-2] = din[L-2] * np.array(sigd(nin[L-1]))\n",
        "                dw[L-2] = (learn_rate * d[L-2]) * n[L-2].reshape((-1, 1))\n",
        "\n",
        "            # Update weights\n",
        "            for i in range(len(w)):\n",
        "                w[i] += dw[i]\n",
        "\n",
        "        mse /= len(X)\n",
        "\n",
        "        if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
        "            print(f'Epoch {epoch}, MSE: {mse}')\n",
        "\n",
        "    return w, epoch, mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJA_9btdc3ED"
      },
      "source": [
        "### c) Fungsi *Testing* Backpropagation\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zyXIu_ec9go"
      },
      "source": [
        "def bp_predict(X, w):\n",
        "  n = [np.empty(len(i)) for i in w]\n",
        "  nin = [np.empty(len(i[0])) for i in w]\n",
        "  predict = []\n",
        "\n",
        "  n.append(np.empty(len(w[-1][0])))\n",
        "\n",
        "  for x in X:\n",
        "    n[0][:-1] = x\n",
        "\n",
        "    for L in range(0, len(w)):\n",
        "      nin[L] = np.dot(n[L], w[L])\n",
        "      n[L + 1][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "    predict.append(n[-1].copy())\n",
        "\n",
        "  return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZxy_M5Jc-ko"
      },
      "source": [
        "### d) Percobaan Klasifikasi Dataset Iris\n",
        "\n",
        "![Iris Dataset](https://www.spataru.at/images/blog/iris-dataset-svm/iris_types.jpg)\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1L_Q3JdHk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7b86ce-fc86-420b-f462-db3f50148abe"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(4, 3, 3), learn_rate=0.1, max_epoch=1000, max_error=0.1, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "\n",
        "print('Output:', predict)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, MSE: 0.4573000553790559\n",
            "Epoch 50, MSE: 0.321272689922169\n",
            "Epoch 75, MSE: 0.2668003450939322\n",
            "Epoch 100, MSE: 0.19045841193641896\n",
            "Epoch 125, MSE: 0.13206064032817524\n",
            "Epoch 150, MSE: 0.10002434429710472\n",
            "Epochs: 151, MSE: 0.09910797309769231\n",
            "Output: [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "True : [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Soal**"
      ],
      "metadata": {
        "id": "N3sMVl6xI7V_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nomor 1"
      ],
      "metadata": {
        "id": "NFW6EPj3M6fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(4, 2, 3), learn_rate=0.1, max_epoch=100, max_error=0.5, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "# Testing on training data\n",
        "train_predict = bp_predict(X_train, w)\n",
        "train_predict = onehot_dec(train_predict)\n",
        "y_train_dec = onehot_dec(y_train)\n",
        "train_accuracy = accuracy_score(train_predict, y_train_dec)\n",
        "\n",
        "print('Train Output:', train_predict)\n",
        "print('Train True :', y_train_dec)\n",
        "print('Train Accuracy:', train_accuracy)\n",
        "\n",
        "# Testing on test data\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test_dec = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test_dec)\n",
        "\n",
        "print('Test Output:', predict)\n",
        "print('Test True :', y_test_dec)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k_V94XxGjLK",
        "outputId": "22fa6893-0a85-41f9-c3fc-3f943f8dfd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, MSE: 0.5587148548510855\n",
            "Epochs: 29, MSE: 0.49569003845261594\n",
            "Train Output: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Train True : [2 0 0 0 1 0 0 2 2 2 2 2 1 2 1 0 2 2 0 0 2 0 2 2 1 1 2 2 0 1 1 2 1 2 1 0 0\n",
            " 0 2 0 1 2 2 0 0 1 0 2 1 2 2 1 2 2 1 0 1 0 1 1 0 1 0 0 2 2 2 0 0 1 0 2 0 2\n",
            " 2 0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 2 2 1 2 0]\n",
            "Train Accuracy: 0.3523809523809524\n",
            "Test Output: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2]\n",
            "Test True : [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "Test Accuracy: 0.28888888888888886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nomor 2"
      ],
      "metadata": {
        "id": "xiabK9CINBMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(4, 25, 3), learn_rate=0.1, max_epoch=10000, max_error=0.01, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "# Testing on training data\n",
        "train_predict = bp_predict(X_train, w)\n",
        "train_predict = onehot_dec(train_predict)\n",
        "y_train_dec = onehot_dec(y_train)\n",
        "train_accuracy = accuracy_score(train_predict, y_train_dec)\n",
        "\n",
        "print('Train Output:', train_predict)\n",
        "print('Train True :', y_train_dec)\n",
        "print('Train Accuracy:', train_accuracy)\n",
        "\n",
        "# Testing on test data\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test_dec = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test_dec)\n",
        "\n",
        "print('Test Output:', predict)\n",
        "print('Test True :', y_test_dec)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT3oeZyeNC6k",
        "outputId": "ee29ce8a-65f8-492a-ecaf-389a98bdd6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, MSE: 1.9997475602526067\n",
            "Epoch 50, MSE: 1.9996839107720699\n",
            "Epoch 75, MSE: 1.9995729256252905\n",
            "Epoch 100, MSE: 1.9993234166160632\n",
            "Epoch 125, MSE: 1.998004842894972\n",
            "Epoch 150, MSE: 1.5034310711672474\n",
            "Epoch 175, MSE: 0.9882734055300789\n",
            "Epoch 200, MSE: 0.9358385629366138\n",
            "Epoch 225, MSE: 0.8962403847767554\n",
            "Epoch 250, MSE: 0.5720113088188044\n",
            "Epoch 275, MSE: 0.1718964155883048\n",
            "Epoch 300, MSE: 0.13551945448567226\n",
            "Epoch 325, MSE: 0.10976277201695424\n",
            "Epoch 350, MSE: 0.09159154648169049\n",
            "Epoch 375, MSE: 0.07929291362007068\n",
            "Epoch 400, MSE: 0.07095077966556529\n",
            "Epoch 425, MSE: 0.06511610472051664\n",
            "Epoch 450, MSE: 0.06088086243803241\n",
            "Epoch 475, MSE: 0.05769828099112584\n",
            "Epoch 500, MSE: 0.05523313404391771\n",
            "Epoch 525, MSE: 0.05327321999520479\n",
            "Epoch 550, MSE: 0.051680019060663\n",
            "Epoch 575, MSE: 0.05036062409674887\n",
            "Epoch 600, MSE: 0.0492511427801703\n",
            "Epoch 625, MSE: 0.04830653743243751\n",
            "Epoch 650, MSE: 0.0474942479018858\n",
            "Epoch 675, MSE: 0.0467901200965703\n",
            "Epoch 700, MSE: 0.046175774075554316\n",
            "Epoch 725, MSE: 0.04563688398575027\n",
            "Epoch 750, MSE: 0.04516204040471443\n",
            "Epoch 775, MSE: 0.04474198671995556\n",
            "Epoch 800, MSE: 0.04436909700191669\n",
            "Epoch 825, MSE: 0.04403701092671842\n",
            "Epoch 850, MSE: 0.043740371938100424\n",
            "Epoch 875, MSE: 0.043474634324519354\n",
            "Epoch 900, MSE: 0.04323591723896495\n",
            "Epoch 925, MSE: 0.04302089148908974\n",
            "Epoch 950, MSE: 0.04282668984054099\n",
            "Epoch 975, MSE: 0.04265083467662363\n",
            "Epoch 1000, MSE: 0.04249117882287875\n",
            "Epoch 1025, MSE: 0.042345856604053364\n",
            "Epoch 1050, MSE: 0.04221324302029275\n",
            "Epoch 1075, MSE: 0.04209191947439559\n",
            "Epoch 1100, MSE: 0.04198064485431984\n",
            "Epoch 1125, MSE: 0.04187833103726308\n",
            "Epoch 1150, MSE: 0.041784022072011366\n",
            "Epoch 1175, MSE: 0.04169687643867343\n",
            "Epoch 1200, MSE: 0.041616151894331044\n",
            "Epoch 1225, MSE: 0.04154119249909171\n",
            "Epoch 1250, MSE: 0.04147141748576008\n",
            "Epoch 1275, MSE: 0.041406311692066815\n",
            "Epoch 1300, MSE: 0.04134541732002254\n",
            "Epoch 1325, MSE: 0.04128832682462402\n",
            "Epoch 1350, MSE: 0.04123467676538137\n",
            "Epoch 1375, MSE: 0.04118414248015849\n",
            "Epoch 1400, MSE: 0.04113643346257424\n",
            "Epoch 1425, MSE: 0.04109128934241915\n",
            "Epoch 1450, MSE: 0.04104847638383636\n",
            "Epoch 1475, MSE: 0.041007784428856976\n",
            "Epoch 1500, MSE: 0.0409690242246994\n",
            "Epoch 1525, MSE: 0.04093202508235701\n",
            "Epoch 1550, MSE: 0.04089663282169357\n",
            "Epoch 1575, MSE: 0.04086270796477128\n",
            "Epoch 1600, MSE: 0.0408301241446381\n",
            "Epoch 1625, MSE: 0.04079876670146962\n",
            "Epoch 1650, MSE: 0.04076853144192072\n",
            "Epoch 1675, MSE: 0.04073932354090524\n",
            "Epoch 1700, MSE: 0.040711056567894595\n",
            "Epoch 1725, MSE: 0.0406836516222629\n",
            "Epoch 1750, MSE: 0.04065703656430092\n",
            "Epoch 1775, MSE: 0.040631145330300766\n",
            "Epoch 1800, MSE: 0.04060591732165031\n",
            "Epoch 1825, MSE: 0.04058129685918402\n",
            "Epoch 1850, MSE: 0.04055723269517248\n",
            "Epoch 1875, MSE: 0.04053367757630275\n",
            "Epoch 1900, MSE: 0.040510587851844915\n",
            "Epoch 1925, MSE: 0.04048792312192261\n",
            "Epoch 1950, MSE: 0.04046564592144081\n",
            "Epoch 1975, MSE: 0.04044372143576321\n",
            "Epoch 2000, MSE: 0.040422117244710315\n",
            "Epoch 2025, MSE: 0.040400803091862274\n",
            "Epoch 2050, MSE: 0.04037975067650614\n",
            "Epoch 2075, MSE: 0.04035893346589022\n",
            "Epoch 2100, MSE: 0.04033832652571127\n",
            "Epoch 2125, MSE: 0.04031790636701102\n",
            "Epoch 2150, MSE: 0.04029765080786386\n",
            "Epoch 2175, MSE: 0.04027753884842159\n",
            "Epoch 2200, MSE: 0.04025755055804552\n",
            "Epoch 2225, MSE: 0.040237666973394835\n",
            "Epoch 2250, MSE: 0.0402178700064656\n",
            "Epoch 2275, MSE: 0.0401981423616813\n",
            "Epoch 2300, MSE: 0.04017846746123178\n",
            "Epoch 2325, MSE: 0.040158829377938056\n",
            "Epoch 2350, MSE: 0.040139212774988935\n",
            "Epoch 2375, MSE: 0.04011960285196158\n",
            "Epoch 2400, MSE: 0.040099985296582194\n",
            "Epoch 2425, MSE: 0.04008034624173274\n",
            "Epoch 2450, MSE: 0.040060672227244465\n",
            "Epoch 2475, MSE: 0.040040950166043816\n",
            "Epoch 2500, MSE: 0.04002116731424922\n",
            "Epoch 2525, MSE: 0.04000131124482988\n",
            "Epoch 2550, MSE: 0.03998136982445211\n",
            "Epoch 2575, MSE: 0.03996133119315698\n",
            "Epoch 2600, MSE: 0.03994118374651078\n",
            "Epoch 2625, MSE: 0.03992091611988698\n",
            "Epoch 2650, MSE: 0.03990051717453426\n",
            "Epoch 2675, MSE: 0.03987997598509456\n",
            "Epoch 2700, MSE: 0.039859281828235914\n",
            "Epoch 2725, MSE: 0.03983842417207373\n",
            "Epoch 2750, MSE: 0.039817392666053365\n",
            "Epoch 2775, MSE: 0.0397961771309847\n",
            "Epoch 2800, MSE: 0.03977476754892064\n",
            "Epoch 2825, MSE: 0.03975315405259321\n",
            "Epoch 2850, MSE: 0.0397313269141337\n",
            "Epoch 2875, MSE: 0.03970927653282524\n",
            "Epoch 2900, MSE: 0.03968699342166378\n",
            "Epoch 2925, MSE: 0.03966446819252598\n",
            "Epoch 2950, MSE: 0.03964169153978162\n",
            "Epoch 2975, MSE: 0.03961865422221429\n",
            "Epoch 3000, MSE: 0.03959534704315792\n",
            "Epoch 3025, MSE: 0.03957176082878905\n",
            "Epoch 3050, MSE: 0.03954788640455633\n",
            "Epoch 3075, MSE: 0.03952371456976565\n",
            "Epoch 3100, MSE: 0.03949923607037551\n",
            "Epoch 3125, MSE: 0.039474441570090606\n",
            "Epoch 3150, MSE: 0.03944932161987461\n",
            "Epoch 3175, MSE: 0.03942386662602588\n",
            "Epoch 3200, MSE: 0.039398066816982796\n",
            "Epoch 3225, MSE: 0.03937191220904433\n",
            "Epoch 3250, MSE: 0.03934539257119211\n",
            "Epoch 3275, MSE: 0.039318497389217284\n",
            "Epoch 3300, MSE: 0.03929121582934155\n",
            "Epoch 3325, MSE: 0.039263536701522425\n",
            "Epoch 3350, MSE: 0.03923544842261427\n",
            "Epoch 3375, MSE: 0.03920693897954814\n",
            "Epoch 3400, MSE: 0.03917799589266306\n",
            "Epoch 3425, MSE: 0.03914860617930833\n",
            "Epoch 3450, MSE: 0.0391187563178032\n",
            "Epoch 3475, MSE: 0.03908843221182618\n",
            "Epoch 3500, MSE: 0.03905761915527104\n",
            "Epoch 3525, MSE: 0.03902630179758832\n",
            "Epoch 3550, MSE: 0.03899446410961403\n",
            "Epoch 3575, MSE: 0.038962089349859445\n",
            "Epoch 3600, MSE: 0.03892916003122997\n",
            "Epoch 3625, MSE: 0.03889565788812207\n",
            "Epoch 3650, MSE: 0.03886156384384855\n",
            "Epoch 3675, MSE: 0.03882685797832764\n",
            "Epoch 3700, MSE: 0.03879151949598367\n",
            "Epoch 3725, MSE: 0.03875552669380464\n",
            "Epoch 3750, MSE: 0.03871885692951322\n",
            "Epoch 3775, MSE: 0.03868148658982159\n",
            "Epoch 3800, MSE: 0.03864339105875627\n",
            "Epoch 3825, MSE: 0.0386045446860585\n",
            "Epoch 3850, MSE: 0.0385649207556903\n",
            "Epoch 3875, MSE: 0.03852449145450279\n",
            "Epoch 3900, MSE: 0.038483227841153676\n",
            "Epoch 3925, MSE: 0.03844109981538981\n",
            "Epoch 3950, MSE: 0.038398076087853755\n",
            "Epoch 3975, MSE: 0.03835412415060239\n",
            "Epoch 4000, MSE: 0.038309210248576045\n",
            "Epoch 4025, MSE: 0.03826329935229458\n",
            "Epoch 4050, MSE: 0.038216355132106465\n",
            "Epoch 4075, MSE: 0.03816833993436945\n",
            "Epoch 4100, MSE: 0.038119214759992165\n",
            "Epoch 4125, MSE: 0.03806893924582304\n",
            "Epoch 4150, MSE: 0.038017471649437\n",
            "Epoch 4175, MSE: 0.037964768837925766\n",
            "Epoch 4200, MSE: 0.037910786281372184\n",
            "Epoch 4225, MSE: 0.03785547805174972\n",
            "Epoch 4250, MSE: 0.03779879682806267\n",
            "Epoch 4275, MSE: 0.037740693908612385\n",
            "Epoch 4300, MSE: 0.03768111923134608\n",
            "Epoch 4325, MSE: 0.03762002140331841\n",
            "Epoch 4350, MSE: 0.03755734774035922\n",
            "Epoch 4375, MSE: 0.03749304431811219\n",
            "Epoch 4400, MSE: 0.03742705603566368\n",
            "Epoch 4425, MSE: 0.037359326693033226\n",
            "Epoch 4450, MSE: 0.037289799083837276\n",
            "Epoch 4475, MSE: 0.037218415104462325\n",
            "Epoch 4500, MSE: 0.037145115881094065\n",
            "Epoch 4525, MSE: 0.03706984191593342\n",
            "Epoch 4550, MSE: 0.03699253325389573\n",
            "Epoch 4575, MSE: 0.036913129671017335\n",
            "Epoch 4600, MSE: 0.036831570885698\n",
            "Epoch 4625, MSE: 0.03674779679376237\n",
            "Epoch 4650, MSE: 0.03666174772814465\n",
            "Epoch 4675, MSE: 0.03657336474377154\n",
            "Epoch 4700, MSE: 0.03648258992794089\n",
            "Epoch 4725, MSE: 0.03638936673615914\n",
            "Epoch 4750, MSE: 0.03629364035302424\n",
            "Epoch 4775, MSE: 0.036195358077294765\n",
            "Epoch 4800, MSE: 0.03609446972980326\n",
            "Epoch 4825, MSE: 0.03599092808233264\n",
            "Epoch 4850, MSE: 0.03588468930499593\n",
            "Epoch 4875, MSE: 0.03577571342905236\n",
            "Epoch 4900, MSE: 0.03566396482145556\n",
            "Epoch 4925, MSE: 0.0355494126668\n",
            "Epoch 4950, MSE: 0.03543203145169679\n",
            "Epoch 4975, MSE: 0.035311801446020974\n",
            "Epoch 5000, MSE: 0.035188709174920875\n",
            "Epoch 5025, MSE: 0.035062747875020436\n",
            "Epoch 5050, MSE: 0.034933917927866445\n",
            "Epoch 5075, MSE: 0.03480222726343396\n",
            "Epoch 5100, MSE: 0.03466769172639575\n",
            "Epoch 5125, MSE: 0.03453033539792668\n",
            "Epoch 5150, MSE: 0.034390190866051565\n",
            "Epoch 5175, MSE: 0.03424729943797653\n",
            "Epoch 5200, MSE: 0.03410171128846151\n",
            "Epoch 5225, MSE: 0.0339534855391037\n",
            "Epoch 5250, MSE: 0.03380269026438378\n",
            "Epoch 5275, MSE: 0.0336494024214681\n",
            "Epoch 5300, MSE: 0.033493707702031285\n",
            "Epoch 5325, MSE: 0.03333570030572707\n",
            "Epoch 5350, MSE: 0.03317548263635408\n",
            "Epoch 5375, MSE: 0.03301316492319496\n",
            "Epoch 5400, MSE: 0.03284886477139735\n",
            "Epoch 5425, MSE: 0.03268270664658917\n",
            "Epoch 5450, MSE: 0.032514821300098244\n",
            "Epoch 5475, MSE: 0.03234534514218705\n",
            "Epoch 5500, MSE: 0.03217441957154562\n",
            "Epoch 5525, MSE: 0.032002190269903856\n",
            "Epoch 5550, MSE: 0.03182880647101622\n",
            "Epoch 5575, MSE: 0.03165442021342979\n",
            "Epoch 5600, MSE: 0.031479185586368065\n",
            "Epoch 5625, MSE: 0.03130325797777894\n",
            "Epoch 5650, MSE: 0.0311267933331105\n",
            "Epoch 5675, MSE: 0.0309499474327324\n",
            "Epoch 5700, MSE: 0.03077287519514472\n",
            "Epoch 5725, MSE: 0.030595730012229885\n",
            "Epoch 5750, MSE: 0.03041866312187084\n",
            "Epoch 5775, MSE: 0.030241823022282715\n",
            "Epoch 5800, MSE: 0.030065354931438176\n",
            "Epoch 5825, MSE: 0.029889400294027306\n",
            "Epoch 5850, MSE: 0.029714096337501845\n",
            "Epoch 5875, MSE: 0.02953957567793918\n",
            "Epoch 5900, MSE: 0.02936596597571896\n",
            "Epoch 5925, MSE: 0.02919338964036561\n",
            "Epoch 5950, MSE: 0.029021963583346976\n",
            "Epoch 5975, MSE: 0.02885179901716757\n",
            "Epoch 6000, MSE: 0.0286830012987159\n",
            "Epoch 6025, MSE: 0.028515669814544498\n",
            "Epoch 6050, MSE: 0.02834989790554328\n",
            "Epoch 6075, MSE: 0.028185772828329323\n",
            "Epoch 6100, MSE: 0.02802337575058952\n",
            "Epoch 6125, MSE: 0.027862781777578543\n",
            "Epoch 6150, MSE: 0.027704060006984874\n",
            "Epoch 6175, MSE: 0.02754727360941881\n",
            "Epoch 6200, MSE: 0.02739247993184751\n",
            "Epoch 6225, MSE: 0.027239730621391307\n",
            "Epoch 6250, MSE: 0.02708907176700408\n",
            "Epoch 6275, MSE: 0.02694054405667822\n",
            "Epoch 6300, MSE: 0.02679418294793605\n",
            "Epoch 6325, MSE: 0.026650018849508916\n",
            "Epoch 6350, MSE: 0.02650807731222444\n",
            "Epoch 6375, MSE: 0.026368379227267993\n",
            "Epoch 6400, MSE: 0.02623094103010568\n",
            "Epoch 6425, MSE: 0.0260957749084912\n",
            "Epoch 6450, MSE: 0.025962889013103854\n",
            "Epoch 6475, MSE: 0.025832287669485678\n",
            "Epoch 6500, MSE: 0.02570397159006642\n",
            "Epoch 6525, MSE: 0.025577938085178067\n",
            "Epoch 6550, MSE: 0.02545418127207004\n",
            "Epoch 6575, MSE: 0.02533269228104163\n",
            "Epoch 6600, MSE: 0.025213459457906026\n",
            "Epoch 6625, MSE: 0.02509646856209821\n",
            "Epoch 6650, MSE: 0.024981702959824412\n",
            "Epoch 6675, MSE: 0.02486914381173962\n",
            "Epoch 6700, MSE: 0.024758770254715897\n",
            "Epoch 6725, MSE: 0.024650559577340803\n",
            "Epoch 6750, MSE: 0.024544487388853564\n",
            "Epoch 6775, MSE: 0.024440527781290838\n",
            "Epoch 6800, MSE: 0.024338653484675756\n",
            "Epoch 6825, MSE: 0.024238836015134935\n",
            "Epoch 6850, MSE: 0.02414104581588199\n",
            "Epoch 6875, MSE: 0.02404525239104899\n",
            "Epoch 6900, MSE: 0.023951424432390744\n",
            "Epoch 6925, MSE: 0.023859529938921018\n",
            "Epoch 6950, MSE: 0.023769536329575333\n",
            "Epoch 6975, MSE: 0.02368141054902208\n",
            "Epoch 7000, MSE: 0.0235951191667695\n",
            "Epoch 7025, MSE: 0.0235106284697382\n",
            "Epoch 7050, MSE: 0.0234279045484868\n",
            "Epoch 7075, MSE: 0.023346913377293707\n",
            "Epoch 7100, MSE: 0.023267620888311153\n",
            "Epoch 7125, MSE: 0.023189993040016253\n",
            "Epoch 7150, MSE: 0.023113995880192896\n",
            "Epoch 7175, MSE: 0.023039595603681733\n",
            "Epoch 7200, MSE: 0.02296675860514043\n",
            "Epoch 7225, MSE: 0.022895451527055837\n",
            "Epoch 7250, MSE: 0.022825641303251404\n",
            "Epoch 7275, MSE: 0.022757295198129572\n",
            "Epoch 7300, MSE: 0.022690380841887292\n",
            "Epoch 7325, MSE: 0.022624866261938204\n",
            "Epoch 7350, MSE: 0.022560719910768922\n",
            "Epoch 7375, MSE: 0.022497910690453343\n",
            "Epoch 7400, MSE: 0.022436407974039597\n",
            "Epoch 7425, MSE: 0.022376181624019442\n",
            "Epoch 7450, MSE: 0.022317202008080468\n",
            "Epoch 7475, MSE: 0.022259440012335503\n",
            "Epoch 7500, MSE: 0.022202867052213405\n",
            "Epoch 7525, MSE: 0.022147455081188896\n",
            "Epoch 7550, MSE: 0.022093176597520373\n",
            "Epoch 7575, MSE: 0.022040004649154458\n",
            "Epoch 7600, MSE: 0.02198791283695117\n",
            "Epoch 7625, MSE: 0.021936875316371778\n",
            "Epoch 7650, MSE: 0.021886866797766143\n",
            "Epoch 7675, MSE: 0.021837862545385747\n",
            "Epoch 7700, MSE: 0.02178983837524408\n",
            "Epoch 7725, MSE: 0.02174277065193548\n",
            "Epoch 7750, MSE: 0.02169663628451825\n",
            "Epoch 7775, MSE: 0.021651412721560133\n",
            "Epoch 7800, MSE: 0.021607077945437907\n",
            "Epoch 7825, MSE: 0.021563610465975956\n",
            "Epoch 7850, MSE: 0.02152098931350288\n",
            "Epoch 7875, MSE: 0.02147919403139971\n",
            "Epoch 7900, MSE: 0.021438204668207405\n",
            "Epoch 7925, MSE: 0.02139800176935503\n",
            "Epoch 7950, MSE: 0.0213585663685682\n",
            "Epoch 7975, MSE: 0.021319879979008624\n",
            "Epoch 8000, MSE: 0.02128192458419401\n",
            "Epoch 8025, MSE: 0.0212446826287435\n",
            "Epoch 8050, MSE: 0.02120813700898713\n",
            "Epoch 8075, MSE: 0.021172271063478368\n",
            "Epoch 8100, MSE: 0.02113706856344159\n",
            "Epoch 8125, MSE: 0.02110251370318516\n",
            "Epoch 8150, MSE: 0.021068591090508695\n",
            "Epoch 8175, MSE: 0.021035285737126628\n",
            "Epoch 8200, MSE: 0.02100258304913307\n",
            "Epoch 8225, MSE: 0.020970468817525827\n",
            "Epoch 8250, MSE: 0.020938929208807227\n",
            "Epoch 8275, MSE: 0.020907950755678785\n",
            "Epoch 8300, MSE: 0.020877520347841953\n",
            "Epoch 8325, MSE: 0.02084762522291705\n",
            "Epoch 8350, MSE: 0.020818252957492282\n",
            "Epoch 8375, MSE: 0.020789391458310647\n",
            "Epoch 8400, MSE: 0.02076102895360209\n",
            "Epoch 8425, MSE: 0.02073315398456934\n",
            "Epoch 8450, MSE: 0.020705755397030214\n",
            "Epoch 8475, MSE: 0.020678822333224017\n",
            "Epoch 8500, MSE: 0.020652344223782013\n",
            "Epoch 8525, MSE: 0.020626310779867905\n",
            "Epoch 8550, MSE: 0.02060071198548839\n",
            "Epoch 8575, MSE: 0.020575538089975788\n",
            "Epoch 8600, MSE: 0.020550779600643127\n",
            "Epoch 8625, MSE: 0.020526427275612227\n",
            "Epoch 8650, MSE: 0.020502472116814528\n",
            "Epoch 8675, MSE: 0.020478905363163092\n",
            "Epoch 8700, MSE: 0.020455718483896\n",
            "Epoch 8725, MSE: 0.02043290317208831\n",
            "Epoch 8750, MSE: 0.02041045133833199\n",
            "Epoch 8775, MSE: 0.020388355104580928\n",
            "Epoch 8800, MSE: 0.020366606798159114\n",
            "Epoch 8825, MSE: 0.02034519894592991\n",
            "Epoch 8850, MSE: 0.020324124268623053\n",
            "Epoch 8875, MSE: 0.020303375675317026\n",
            "Epoch 8900, MSE: 0.020282946258074645\n",
            "Epoch 8925, MSE: 0.020262829286727162\n",
            "Epoch 8950, MSE: 0.020243018203805363\n",
            "Epoch 8975, MSE: 0.020223506619614376\n",
            "Epoch 9000, MSE: 0.020204288307448075\n",
            "Epoch 9025, MSE: 0.02018535719894098\n",
            "Epoch 9050, MSE: 0.020166707379553943\n",
            "Epoch 9075, MSE: 0.020148333084190055\n",
            "Epoch 9100, MSE: 0.020130228692938686\n",
            "Epoch 9125, MSE: 0.020112388726943303\n",
            "Epoch 9150, MSE: 0.020094807844390314\n",
            "Epoch 9175, MSE: 0.020077480836615955\n",
            "Epoch 9200, MSE: 0.020060402624327983\n",
            "Epoch 9225, MSE: 0.020043568253939038\n",
            "Epoch 9250, MSE: 0.020026972894008465\n",
            "Epoch 9275, MSE: 0.020010611831790242\n",
            "Epoch 9300, MSE: 0.019994480469883006\n",
            "Epoch 9325, MSE: 0.01997857432298042\n",
            "Epoch 9350, MSE: 0.01996288901471828\n",
            "Epoch 9375, MSE: 0.019947420274615907\n",
            "Epoch 9400, MSE: 0.019932163935108802\n",
            "Epoch 9425, MSE: 0.019917115928670397\n",
            "Epoch 9450, MSE: 0.01990227228501987\n",
            "Epoch 9475, MSE: 0.01988762912841347\n",
            "Epoch 9500, MSE: 0.019873182675017267\n",
            "Epoch 9525, MSE: 0.019858929230358303\n",
            "Epoch 9550, MSE: 0.01984486518685261\n",
            "Epoch 9575, MSE: 0.019830987021406912\n",
            "Epoch 9600, MSE: 0.019817291293092204\n",
            "Epoch 9625, MSE: 0.01980377464088707\n",
            "Epoch 9650, MSE: 0.019790433781488603\n",
            "Epoch 9675, MSE: 0.01977726550718879\n",
            "Epoch 9700, MSE: 0.019764266683813994\n",
            "Epoch 9725, MSE: 0.01975143424872671\n",
            "Epoch 9750, MSE: 0.019738765208886025\n",
            "Epoch 9775, MSE: 0.019726256638966762\n",
            "Epoch 9800, MSE: 0.019713905679533912\n",
            "Epoch 9825, MSE: 0.019701709535271755\n",
            "Epoch 9850, MSE: 0.019689665473265432\n",
            "Epoch 9875, MSE: 0.019677770821333786\n",
            "Epoch 9900, MSE: 0.01966602296641068\n",
            "Epoch 9925, MSE: 0.019654419352975523\n",
            "Epoch 9950, MSE: 0.019642957481529\n",
            "Epoch 9975, MSE: 0.01963163490711445\n",
            "Epoch 10000, MSE: 0.019620449237882337\n",
            "Epochs: 10000, MSE: 0.019620449237882337\n",
            "Train Output: [2 0 0 0 1 0 0 2 2 2 2 2 1 2 1 0 2 2 0 0 2 0 2 2 1 1 2 2 0 1 1 2 1 2 1 0 0\n",
            " 0 2 0 2 2 2 0 0 1 0 2 1 2 2 1 2 2 1 0 1 0 1 1 0 1 0 0 2 2 2 0 0 1 0 2 0 2\n",
            " 2 0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 2 2 1 2 0]\n",
            "Train True : [2 0 0 0 1 0 0 2 2 2 2 2 1 2 1 0 2 2 0 0 2 0 2 2 1 1 2 2 0 1 1 2 1 2 1 0 0\n",
            " 0 2 0 1 2 2 0 0 1 0 2 1 2 2 1 2 2 1 0 1 0 1 1 0 1 0 0 2 2 2 0 0 1 0 2 0 2\n",
            " 2 0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 2 2 1 2 0]\n",
            "Train Accuracy: 0.9904761904761905\n",
            "Test Output: [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 2 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 1 2 1]\n",
            "Test True : [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "Test Accuracy: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nomor 3"
      ],
      "metadata": {
        "id": "vaOeJGMBzUA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(4, 4, 3), learn_rate=0.1, max_epoch=850, max_error=0.01, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "# Testing on training data\n",
        "train_predict = bp_predict(X_train, w)\n",
        "train_predict = onehot_dec(train_predict)\n",
        "y_train_dec = onehot_dec(y_train)\n",
        "train_accuracy = accuracy_score(train_predict, y_train_dec)\n",
        "\n",
        "print('Train Output:', train_predict)\n",
        "print('Train True :', y_train_dec)\n",
        "print('Train Accuracy:', train_accuracy)\n",
        "\n",
        "# Testing on test data\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test_dec = onehot_dec(y_test)\n",
        "accuracy = accuracy_score(predict, y_test_dec)\n",
        "\n",
        "print('Test Output:', predict)\n",
        "print('Test True :', y_test_dec)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsElv6rHzVKX",
        "outputId": "53182232-4970-43f4-fd35-b15d5d37ba67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, MSE: 0.4037189784961099\n",
            "Epoch 50, MSE: 0.30392164211321915\n",
            "Epoch 75, MSE: 0.2467626574560707\n",
            "Epoch 100, MSE: 0.18371215918575698\n",
            "Epoch 125, MSE: 0.13722833341171944\n",
            "Epoch 150, MSE: 0.10766703344361239\n",
            "Epoch 175, MSE: 0.0891059387107455\n",
            "Epoch 200, MSE: 0.07720900091073199\n",
            "Epoch 225, MSE: 0.06928833189909853\n",
            "Epoch 250, MSE: 0.06377510363938882\n",
            "Epoch 275, MSE: 0.05976793063739653\n",
            "Epoch 300, MSE: 0.056741123292045205\n",
            "Epoch 325, MSE: 0.05437885321180183\n",
            "Epoch 350, MSE: 0.052484652174752\n",
            "Epoch 375, MSE: 0.05093188930466216\n",
            "Epoch 400, MSE: 0.04963608911914036\n",
            "Epoch 425, MSE: 0.048539022400874925\n",
            "Epoch 450, MSE: 0.04759929543082216\n",
            "Epoch 475, MSE: 0.04678662643979523\n",
            "Epoch 500, MSE: 0.04607827250402464\n",
            "Epoch 525, MSE: 0.045456743342417276\n",
            "Epoch 550, MSE: 0.04490830362959628\n",
            "Epoch 575, MSE: 0.04442196901975075\n",
            "Epoch 600, MSE: 0.04398881760969524\n",
            "Epoch 625, MSE: 0.04360150689804629\n",
            "Epoch 650, MSE: 0.04325392722033676\n",
            "Epoch 675, MSE: 0.04294094760595845\n",
            "Epoch 700, MSE: 0.042658225482258165\n",
            "Epoch 725, MSE: 0.042402061389145165\n",
            "Epoch 750, MSE: 0.04216928607770713\n",
            "Epoch 775, MSE: 0.041957171379986245\n",
            "Epoch 800, MSE: 0.04176335886689852\n",
            "Epoch 825, MSE: 0.04158580205939107\n",
            "Epoch 850, MSE: 0.041422719137951924\n",
            "Epochs: 850, MSE: 0.041422719137951924\n",
            "Train Output: [2 0 0 0 1 0 0 2 2 2 2 2 1 2 1 0 2 2 0 0 2 0 2 2 1 1 2 2 0 1 1 2 1 2 1 0 0\n",
            " 0 2 0 2 2 2 0 0 1 0 2 1 2 2 1 2 2 1 0 1 0 1 1 0 1 0 0 2 2 2 0 0 2 0 2 0 2\n",
            " 2 0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 1 2 1 2 0]\n",
            "Train True : [2 0 0 0 1 0 0 2 2 2 2 2 1 2 1 0 2 2 0 0 2 0 2 2 1 1 2 2 0 1 1 2 1 2 1 0 0\n",
            " 0 2 0 1 2 2 0 0 1 0 2 1 2 2 1 2 2 1 0 1 0 1 1 0 1 0 0 2 2 2 0 0 1 0 2 0 2\n",
            " 2 0 2 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 2 0 0 2 1 2 1 2 2 1 2 0]\n",
            "Train Accuracy: 0.9714285714285714\n",
            "Test Output: [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "Test True : [0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 2 0 2 2 1]\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}